{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdt_tokenizer.core import MyanmarSyllableTokenizer\n",
    "from mmdt_tokenizer.utils.config import DATA_DIR, OUTPUT_DIR\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "tokenizer = MyanmarSyllableTokenizer()\n",
    "\n",
    "def test_syllable_tokenize_basic(tokenizer:  MyanmarSyllableTokenizer):\n",
    "    text = \"မင်္ဂလာပါ\"\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    assert isinstance(tokens, list)\n",
    "    assert any(\"မင်္\" in tok or \"ဂ\" in tok for tok in tokens[0])\n",
    "\n",
    "def test_syllable_tokenize_multiple_text(tokenizer:  MyanmarSyllableTokenizer):\n",
    "    \"\"\"Tests the CSV saving feature exposed by the main tokenizer.\"\"\"\n",
    "    text = [\"မင်္ဂလာပါ မြန်မာစာ\", \"တနေ့တော့\"]\n",
    "    csv_output_path = OUTPUT_DIR / \"result_syllable_test.csv\"\n",
    "    tokens = tokenizer.tokenize(text,save_csv=str(csv_output_path), conll_style=False)\n",
    "    print(tokens)\n",
    "    assert(len(tokens)==2)\n",
    "    \n",
    "    \n",
    "def test_syllable_tokenize_csv(tokenizer: MyanmarSyllableTokenizer):\n",
    "    \"\"\"Tests the CSV loading/saving feature exposed by the main tokenizer.\"\"\"\n",
    "    csv_input_path = DATA_DIR / \"test_data.csv\"\n",
    "    csv_output_path = OUTPUT_DIR / \"result_syllable_bd.csv\"\n",
    "\n",
    "    df = pd.read_csv(csv_input_path)\n",
    "    \n",
    "    # Call the main tokenizer method with the save_csv argument and input is dataframe\n",
    "    \n",
    "    tokenizer.tokenize(df, column = 'original_sentence', save_csv=str(csv_output_path), conll_style=False)\n",
    "    assert Path(csv_output_path).exists()\n",
    "    \n",
    "\n",
    "test_syllable_tokenize_basic(tokenizer)\n",
    "test_syllable_tokenize_multiple_text(tokenizer)\n",
    "test_syllable_tokenize_csv(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3277bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_postpositions(tokenizer):\n",
    "    text= \"စစ်ရေးအရ တကက-၁၃ ရှိတဲ့ တွင်းငယ်ရွာကြီးကို စစ်တပ်ထိန်းချုပ်လိုက်ပြီးနောက် ၇ မိုင်တပ်စခန်းအနီးက စမ္ပါယ်နဂိုရ်ရွာ၊ ကျောက်ကြီး၊ ဝါးဖြူတောင် စတဲ့နေရာတွေကိုလည်း အဆင့်ဆင့် လက်လွှတ်ခဲ့ရပြီး မြို့ကို ဆုံးရှုံးလိုက်ရတာလို့ မြေပြင်သတင်းရင်းမြစ်တစ်ဦးက ဆိုပါတယ်။\"\n",
    "    #text = \"ကချင်၊ စစ်ကိုင်း နဲ့ ရှမ်း ဒေသသုံးခုပေါင်းဆုံရာ ဗျူဟာမြောက်မြို့ဖြစ်တဲ့ အင်းတော်မြို့ကို တော်လှန်ရေးတပ်တွေ စစ်ဆင်ရေးပြုလုပ်ရာမှာ ABSDF စစ်ကြောင်း ၁ ရဲ့ စစ်ကြောင်းမှူးက ကွပ်ကဲခဲ့ပါတယ်။\"\n",
    "    tokens = tokenizer.word_tokenize(text)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "from mmdt_tokenizer import MyanmarTokenizer\n",
    "tokenizer = MyanmarTokenizer()\n",
    "all_tokens = test_postpositions(tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_word_tokenize_multiple_text(tokenizer):\n",
    "    text = [\"မင်္ဂလာပါ မြန်မာစာ\", \"တနေ့တော့\"]\n",
    "    csv_output_path = OUTPUT_DIR / \"result_word_test.csv\"\n",
    "    tokens = tokenizer.word_tokenize(text,save_csv=str(csv_output_path), conll_style=False)\n",
    "    print(tokens)\n",
    "    \n",
    "    assert(len(tokens)==2)\n",
    "\n",
    "from mmdt_tokenizer import MyanmarTokenizer\n",
    "tokenizer = MyanmarTokenizer()\n",
    "all_tokens = test_word_tokenize_multiple_text(tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
